[使用 CoT 提示和微調測量和提高 LLM 生成的 Python 代碼的效率 |IEEE 期刊和雜誌 |IEEE Xplore --- Measuring and Improving the Efficiency of Python Code Generated by LLMs Using CoT Prompting and Fine-Tuning | IEEE Journals & Magazine | IEEE Xplore](https://ieeexplore.ieee.org/document/11069268)

[通過結構化提示培訓增強數據分析和程式設計技能：生成式人工智慧對工程教育的影響 - ScienceDirect --- Enhancing data analysis and programming skills through structured prompt training: The impact of generative AI in engineering education - ScienceDirect](https://www.sciencedirect.com/science/article/pii/S2666920X25000207)

[使用語言模型進行思維鏈提示，以準確解決數學問題 |IEEE 會議出版物 |IEEE Xplore --- Chain-of-Thoughts Prompting with Language Models for Accurate Math Problem-Solving | IEEE Conference Publication | IEEE Xplore](https://ieeexplore.ieee.org/document/10534945)



### 0.1. LLM生成品質可信度疑慮

儘管LLM在平行設計與高效能運算應用中展現強大潛力，其程式碼生成能力亦逐漸被導入實際開發流程中，但這也引發對其生成品質與執行效率的廣泛關注。但與傳統開發工具相比，LLM生成之程式碼常帶有不確定性，這種預測式生成機制已在自然語言處理（Deanda et al., 2015）、電腦視覺（Zhang et al., 2019）、自動駕駛（He et al., 2024）與醫療保健領域（Deanda et al., 2025）引發類似的可信度疑慮。

在程式碼生成的脈絡中，我們主要關注於LLM所生成程式碼的實際可用性，尤其在硬體受限下的環境更需重視效能指標。常見的衡量指標包括Memory Usage、CPU Utilization、Run Time與、Code Complexity(Coignion et al., 2024; Qiu et al., 2024)。Huang, et al., (2024)提出一套專門評估LLM 生成程式碼正確性與效率的測試集EFFIBENCH。研究指出，即使 LLM 生成的程式碼在功能上是正確的，但在記憶體使用與執行時間方面不如人類撰寫的程式碼(Huang et al., 2024)。此結果歸咎於目前的主流訓練範式為「下一個程式碼 token 預測」，傾向局部模式的補全，而非尋找整體上更有效率的演算法結構(Guo et al., 2024)。儘管語法上正確，但局部補全的方法會產生多餘的程式碼區塊，導致時間與空間複雜度上升，進而造成計算資源的浪費。

LLM 生成程式碼的固有低效率，會使應用程式的執行速度變慢、運作成本上升，甚至無法符合系統需求。尤其是 IoT、邊緣運算系統、雲端裝置等資源受限的環境下部署時，記憶體使用量與執行速度為關鍵考量(Bolón-Canedo et al., 2024; Solovyeva et al., 2025)。Dou et al., (2024)與Hou and Ji (2025) 比較了人類程式設計師與LLM的表現，發現LLM雖然在結構化任務中表現優異，但在面對模糊任務時表現不佳，而人類設計師所撰寫的程式碼在執行時間與記憶體使用方面通常更有效率，也凸顯出當前LLM不足之處。Niu et al., (2024)的研究納入準確率與執行時間作為效率指標，並在HumanEval、MBPP 資料集中(聚焦 Python 問題)，與LeetCodeEval資料集(涵蓋 C++ 題目)上進行測試。結果指出，LLM 的執行效率仍落後於人類所撰寫的程式碼。Paul et al.,(2024)分析了HUMANEVAL(Chen et al., 2021)、MBPP(Austin et al., 2021)等現有資料集，並採用pass@k 作為效能評估指標。pass@k 意旨在 k 次生成中至少成功一次的機率。然而 Paul et al.,(2024)研究的重點為 LLM 所產生程式碼的正確性，對於效率並未關注。Du et al., (2024)提到，程式碼的效率應該被定義在資源消耗最小的情況下完成任務的能力。這樣的程式碼才能提升使用者體驗、節省能源，並使應用更具成本效益。


在訓練資料集上，同時也存在有效與無效的程式碼，這會讓模型對於提示語意產生幻覺(hallucination)，進一步導致不必要的能源消耗與在關鍵應用場景下的效能下降(Huang et al., 2025)。Han et al.（2024）提到，完整的參數微調雖能提升表現，但代價是大量運算資源與潛在的泛化能力下降。雖然 Parameter-Efficient Fine-Tuning（PEFT）策略在一定程度上能降低微調成本，但也容易導致災難性遺忘（catastrophic forgetting），亦即模型可能在新任務表現良好，卻遺失先前已學習的關鍵能力。這也凸顯出採用針對任務語境設計的提示工程（prompt engineering）成為更具可行性與可控性的選項，在不犧牲效率與穩定性的前提下，平衡結果的準確性與可解釋性。


